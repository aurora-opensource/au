#!/usr/bin/python3
# Copyright 2022 Aurora Operations, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.


import argparse
import datetime
import re
import subprocess
import sys


AURORA_COPYRIGHT = "Copyright {year} Aurora Operations, Inc."

APACHE_HEADER = f"""
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License."""


def main(argv=None):
    """
    Print, to stdout, the contents of a single-file version of the input file.

    A "single-file version" means that we directly include the contents of all
    transitively included files which are within the project, but we leave other
    `#include` directives (such as standard library headers) untouched.
    """
    args = parse_command_line_args(argv)
    files = parse_files(
        filenames=filenames(
            main_files=args.main_files, units=args.units, include_io=args.include_io
        )
    )
    print_unified_file(files, args=args)

    return 0


def filenames(main_files, units, include_io):
    """Construct the list of project filenames to include.

    The script will be sure to include all of these, and will also include any
    transitive dependencies from within the project.
    """
    names = ["au/au.hh"] + [f"au/units/{unit}.hh" for unit in units] + main_files
    if include_io:
        names.append("au/io.hh")
    return names


def parse_command_line_args(argv):
    """Read the arguments from the command line."""
    parser = argparse.ArgumentParser()

    parser.add_argument("main_files", nargs="*", help="The main files to aggregate")

    parser.add_argument("--units", nargs="*", default=[], help="The units to include")

    parser.add_argument(
        "--version-id",
        default=git_id_description(),
        help="An identifier for the version of code used to build this file",
    )

    parser.add_argument(
        "--noio",
        action="store_false",
        dest="include_io",
        help="Exclude I/O capabilities",
    )

    return parser.parse_args()


def parse_files(filenames):
    """
    Create a `SourceFile` for each of the transitive includes of `main_file`.
    """
    # Note: this loop is sloppy about preserving the same order.
    # This shouldn't matter as long as it's topologically equivalent.
    files = {}
    while filenames:
        next_file = filenames.pop()
        files[next_file] = SourceFile(filename=next_file)
        for target in files[next_file].graph_includes:
            if target not in files:
                filenames.append(target)

    return files


class SourceFile:
    """
    A structured representation of a file.

    Besides the name, keeps track of project-internal includes, project-external
    includes, and the lines of content in the file.
    """

    def __init__(self, filename):
        self.name = filename
        self.global_includes = []
        self.graph_includes = []
        self.lines = []

        in_copyright_header = False
        with open(filename) as f:
            was_last_line_blank = False
            for line in f:
                if line.startswith("#pragma once"):
                    continue
                if re.search(AURORA_COPYRIGHT.format(year="20.."), line):
                    in_copyright_header = True
                    continue
                if in_copyright_header:
                    if line.startswith("//"):
                        continue
                    else:
                        in_copyright_header = False

                # Collapse consecutive blank lines into one.
                if line.strip():
                    was_last_line_blank = False
                else:
                    if was_last_line_blank:
                        continue
                    was_last_line_blank = True

                # Put this line where it belongs.  If it's an `#include`, sort
                # it with either the project-specific collection
                # ("graph_includes"), or the global collection.  Otherwise,
                # just add it to the list of content lines.
                target = include_target(line)
                if target:
                    if target.startswith("au"):
                        self.graph_includes.append(target)
                    else:
                        self.global_includes.append(line.rstrip())
                else:
                    self.lines.append(line.rstrip())


def include_target(line):
    """The name of the file if this is an `#include` line, else None."""
    m = re.match(r'\#include [<"]([^"]+)[>"]', line)
    return m.group(1) if m else None


def sort_topologically(files):
    """
    Produce a topologically sorted list of the keys of `files`.

    Topological sorting means that no file can appear before any of its
    transitive includes.

    :param files:  A dictionary mapping filenames onto `SourceFile` instances.
    """
    ready_files = []
    unvisited_deps = {f: files[f].graph_includes for f in files}
    while unvisited_deps:
        added_this_cycle = []
        for f in unvisited_deps:
            if not unvisited_deps[f]:
                for f_to_clean in unvisited_deps:
                    if f in unvisited_deps[f_to_clean]:
                        unvisited_deps[f_to_clean].remove(f)

                added_this_cycle.append(f)

        for f in added_this_cycle:
            unvisited_deps.pop(f)

        ready_files.extend(added_this_cycle)
    return ready_files


def include_lines(files):
    """The set of global includes, deduplicated across all project files."""
    return set(line for f in files for line in files[f].global_includes)


def print_unified_file(files, args):
    """Print the single-file output to stdout."""
    print(f"// {AURORA_COPYRIGHT.format(year=datetime.datetime.now().year)}")
    for line in APACHE_HEADER.splitlines():
        print(f"// {line}".rstrip())
    print()
    print("#pragma once")
    print()

    for i in sorted(include_lines(files)):
        print(i)

    print()
    for line in manifest(args=args):
        print(f"// {line}")

    for f in sort_topologically(files):
        for line in files[f].lines:
            print(line)


def manifest(args):
    """A sequence of lines describing the options that generated this file."""
    args = CheckArgs(args)

    lines = [
        f"Version identifier: {args.version_id}",
        f'<iostream> support: {"INCLUDED" if args.include_io else "EXCLUDED"}',
        "List of included units:",
    ] + [f"  {u}" for u in sorted(args.units)]

    if args.main_files:
        lines.append("Extra files included:")
        lines.extend(f"  {f}" for f in sorted(args.main_files))

    assert args.are_all_used()
    return lines


class CheckArgs(dict):
    def __init__(self, args):
        self.vars = vars(args)
        self.used = set()

    def are_all_used(self):
        return not set(self.vars.keys()).difference(self.used)

    def __getattr__(self, k):
        self.used.add(k)
        return self.vars[k]


def git_id_description():
    """A description of the ID (commit or tag) in git, and whether it's clean."""
    # TODO(#21):  The logic for the identifier currently lives in two places.
    # After `make-single-file` becomes a thin wrapper on the underlying logic in
    # python, we can fix this by making the `--version-id` argument _required_,
    # and deleting this function.  (We can have the underlying python rule
    # depend on the existence of the stable version stamp, and simply use that
    # always.)
    try:
        return (
            subprocess.check_output(
                ["git", "describe", "--always", "--dirty"], stderr=subprocess.DEVNULL
            )
            .decode("ascii")
            .strip()
        )
    except subprocess.CalledProcessError:
        # We do not ever expect this line to affect the generated file in normal
        # operations.  If users are running the script manually, then the above
        # command will succeed, because currently the command is not sandboxed.
        # And if users are running a genrule for a pre-built single-file
        # package, then that command is constructed to supply the version
        # information, which means that the below value will be _returned_ but
        # not _used_.
        #
        # Really, the point of the following line is to generate a valid default
        # value (so that the script does not crash) in the cases where we know
        # the default value won't be used.
        return "(Unknown version)"


if __name__ == "__main__":
    sys.exit(main())
